"use strict";(self.webpackChunkopen_models_iecho=self.webpackChunkopen_models_iecho||[]).push([[836],{3905:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>m});var o=n(67294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function l(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?l(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):l(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,o,a=function(e,t){if(null==e)return{};var n,o,a={},l=Object.keys(e);for(o=0;o<l.length;o++)n=l[o],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(o=0;o<l.length;o++)n=l[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var r=o.createContext({}),d=function(e){var t=o.useContext(r),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},u=function(e){var t=d(e.components);return o.createElement(r.Provider,{value:t},e.children)},c="mdxType",h={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},p=o.forwardRef((function(e,t){var n=e.components,a=e.mdxType,l=e.originalType,r=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),c=d(n),p=a,m=c["".concat(r,".").concat(p)]||c[p]||h[p]||l;return n?o.createElement(m,i(i({ref:t},u),{},{components:n})):o.createElement(m,i({ref:t},u))}));function m(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var l=n.length,i=new Array(l);i[0]=p;var s={};for(var r in t)hasOwnProperty.call(t,r)&&(s[r]=t[r]);s.originalType=e,s[c]="string"==typeof e?e:a,i[1]=s;for(var d=2;d<l;d++)i[d]=n[d];return o.createElement.apply(null,i)}return o.createElement.apply(null,n)}p.displayName="MDXCreateElement"},43584:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>r,contentTitle:()=>i,default:()=>h,frontMatter:()=>l,metadata:()=>s,toc:()=>d});var o=n(87462),a=(n(67294),n(3905));const l={},i="Frequently Asked Questions",s={unversionedId:"faq",id:"faq",title:"Frequently Asked Questions",description:"This pages covers specific questions. A more general introduction to the",source:"@site/docs/faq.md",sourceDirName:".",slug:"/faq",permalink:"/open-models-iecho/docs/faq",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"sidebar",previous:{title:"Presentations",permalink:"/open-models-iecho/docs/presentations/"}},r={},d=[{value:"Questions about the project",id:"questions-about-the-project",level:2},{value:"How far along is this project?",id:"how-far-along-is-this-project",level:3},{value:"Is a model ready to test yet?",id:"is-a-model-ready-to-test-yet",level:3},{value:"Can I install Open Models iEcho locally and chat with it?",id:"can-i-install-open-models-iecho-locally-and-chat-with-it",level:3},{value:"Is there an API available?",id:"is-there-an-api-available",level:3},{value:"What is the Docker command in the README for?",id:"what-is-the-docker-command-in-the-readme-for",level:3},{value:"What license does Open Models iEcho use?",id:"what-license-does-open-models-iecho-use",level:3},{value:"Who is behind Open Models iEcho?",id:"who-is-behind-open-models-iecho",level:3},{value:"Will Open Models iEcho be free?",id:"will-open-models-iecho-be-free",level:3},{value:"What hardware will be required to run the models?",id:"what-hardware-will-be-required-to-run-the-models",level:3},{value:"How can I contribute?",id:"how-can-i-contribute",level:3},{value:"What technologies are used?",id:"what-technologies-are-used",level:3},{value:"Questions about the data collection website",id:"questions-about-the-data-collection-website",level:2},{value:"Can I use ChatGPT to help in training Open Models iEcho, for instance, by generating answers?",id:"can-i-use-chatgpt-to-help-in-training-open-models-iecho-for-instance-by-generating-answers",level:3},{value:"What should I do if I don&#39;t know how to complete the task as an assistant?",id:"what-should-i-do-if-i-dont-know-how-to-complete-the-task-as-an-assistant",level:3},{value:"Should I fact check the answers by the assistant?",id:"should-i-fact-check-the-answers-by-the-assistant",level:3},{value:"How can I see my score?",id:"how-can-i-see-my-score",level:3},{value:"Can we see how many data points have been collected?",id:"can-we-see-how-many-data-points-have-been-collected",level:3},{value:"How do I write and label prompts?",id:"how-do-i-write-and-label-prompts",level:3},{value:"Where can I report a bug or create a new feature request?",id:"where-can-i-report-a-bug-or-create-a-new-feature-request",level:3},{value:"Why am I not allowed to write about this topic, even though it isn&#39;t illegal?",id:"why-am-i-not-allowed-to-write-about-this-topic-even-though-it-isnt-illegal",level:3},{value:"Questions about the development process",id:"questions-about-the-development-process",level:2},{value:"Docker-Compose instead of Docker Compose",id:"docker-compose-instead-of-docker-compose",level:3},{value:"Enable Docker&#39;s BuildKit Backend",id:"enable-dockers-buildkit-backend",level:3},{value:"Pre-commit",id:"pre-commit",level:3},{value:"Docker Cannot Start Container: Permission Denied",id:"docker-cannot-start-container-permission-denied",level:3},{value:"Docker Cannot Stop Container",id:"docker-cannot-stop-container",level:3},{value:"Docker Port Problems",id:"docker-port-problems",level:3}],u={toc:d},c="wrapper";function h(e){let{components:t,...n}=e;return(0,a.kt)(c,(0,o.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"frequently-asked-questions"},"Frequently Asked Questions"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"This pages covers specific questions. A more general introduction to the\nproject and its goals can be found\n",(0,a.kt)("a",{parentName:"p",href:"https://projects.open.models.platform/open-models-iecho/docs/intro"},"here"),".")),(0,a.kt)("p",null,"In this page, there are some of the most frequently asked questions."),(0,a.kt)("h2",{id:"questions-about-the-project"},"Questions about the project"),(0,a.kt)("details",null,(0,a.kt)("summary",null,(0,a.kt)("h3",{id:"how-far-along-is-this-project"},"How far along is this project?")),(0,a.kt)("p",null,"We have released candidate supervised finetuning (SFT) models using both Pythia\nand LLaMa, as well as candidate reward models for reinforcement learning from\nhuman feedback training using Pythia, which you can try, and are beginning the\nprocess of applying (RLHF). We have also released the first version of the\nOpenAssistant Conversations dataset\n",(0,a.kt)("a",{parentName:"p",href:"https://huggingface.co/datasets/OpenAssistant/oasst1"},"here"),".")),(0,a.kt)("details",null,(0,a.kt)("summary",null,(0,a.kt)("h3",{id:"is-a-model-ready-to-test-yet"},"Is a model ready to test yet?")),(0,a.kt)("p",null,"You can play with our best candidate model\n",(0,a.kt)("a",{parentName:"p",href:"https://open-models-iecho.io/chat"},"here")," and provide thumbs up/down responses to\nhelp us improve the model in future!")),(0,a.kt)("details",null,(0,a.kt)("summary",null,(0,a.kt)("h3",{id:"can-i-install-open-models-iecho-locally-and-chat-with-it"},"Can I install Open Models iEcho locally and chat with it?")),(0,a.kt)("p",null,"The candidate Pythia SFT models are\n",(0,a.kt)("a",{parentName:"p",href:"https://huggingface.co/OpenAssistant"},"available on HuggingFace")," and can be\nloaded via the HuggingFace Transformers library. As such you may be able to use\nthem with sufficient hardware. There are also spaces on HF which can be used to\nchat with the OA candidate without your own hardware. However, these models are\nnot final and can produce poor or undesirable outputs."),(0,a.kt)("p",null,"LLaMa SFT models cannot be released directly due to Meta's license but XOR\nweights are released on the HuggingFace org. Follow the process in the README\nthere to obtain a full model from these XOR weights.")),(0,a.kt)("details",null,(0,a.kt)("summary",null,(0,a.kt)("h3",{id:"is-there-an-api-available"},"Is there an API available?")),(0,a.kt)("p",null,"There is no API currently available for Open Models iEcho. Any mention of an API in\ndocumentation is referencing the website's internal API. We understand that an\nAPI is a highly requested feature, but unfortunately, we can't provide one at\nthis time due to a couple of reasons. Firstly, the inference system is already\nunder high load and running off of compute from our sponsors. Secondly, the\nproject's primary goal is currently data collection and model training, not\nproviding a product."),(0,a.kt)("p",null,"However, if you're looking to run inference, you can host the model yourself\neither on your own hardware or with a cloud provider. We appreciate your\nunderstanding and patience as we continue to develop this project.")),(0,a.kt)("details",null,(0,a.kt)("summary",null,(0,a.kt)("h3",{id:"what-is-the-docker-command-in-the-readme-for"},"What is the Docker command in the README for?")),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"docker compose")," command in the README is for setting up the project for\nlocal development on the website or data collection backend. It does not launch\nan AI model or the inference server. There is likely no point in running the\ninference setup and UI locally unless you wish to assist in development.")),(0,a.kt)("details",null,(0,a.kt)("summary",null,(0,a.kt)("h3",{id:"what-license-does-open-models-iecho-use"},"What license does Open Models iEcho use?")),(0,a.kt)("p",null,"All Open Models iEcho code is licensed under Apache 2.0. This means it is available\nfor a wide range of uses including commercial use."),(0,a.kt)("p",null,"The Open Models iEcho Pythia based models are released as full weights and will be\nlicensed under the Apache 2.0 license."),(0,a.kt)("p",null,"The Open Models iEcho LLaMa based models will be released only as delta weights\nmeaning you will need the original LLaMa weights to use them, and the license\nrestrictions will therefore be those placed on the LLaMa weights."),(0,a.kt)("p",null,"The Open Models iEcho data is released under a Creative Commons license allowing a\nwide range of uses including commercial use.")),(0,a.kt)("details",null,(0,a.kt)("summary",null,(0,a.kt)("h3",{id:"who-is-behind-open-models-iecho"},"Who is behind Open Models iEcho?")),(0,a.kt)("p",null,"Open Models iEcho is a project organized by ",(0,a.kt)("a",{parentName:"p",href:"https://open.models.platform/"},"Open Models")," and\ndeveloped by a team of volunteers worldwide. You can see an incomplete list of\ndevelopers on ",(0,a.kt)("a",{parentName:"p",href:"https://open-models-iecho.io/team"},"our website"),"."),(0,a.kt)("p",null,"The project would not be possible without the many volunteers who have spent\ntime contributing both to data collection and to the development process. Thank\nyou to everyone who has taken part!")),(0,a.kt)("details",null,(0,a.kt)("summary",null,(0,a.kt)("h3",{id:"will-open-models-iecho-be-free"},"Will Open Models iEcho be free?")),(0,a.kt)("p",null,"The model code, weights, and data are free. We are additionally hosting a free\npublic instance of our best current model for as long as we can thanks to\ncompute donation from Stability AI via Open Models!")),(0,a.kt)("details",null,(0,a.kt)("summary",null,(0,a.kt)("h3",{id:"what-hardware-will-be-required-to-run-the-models"},"What hardware will be required to run the models?")),(0,a.kt)("p",null,"The current smallest (Pythia) model is 12B parameters and is challenging to run\non consumer hardware, but can run on a single professional GPU. In future there\nmay be smaller models and we hope to make progress on methods like integer\nquantisation which can help run the model on smaller hardware.")),(0,a.kt)("details",null,(0,a.kt)("summary",null,(0,a.kt)("h3",{id:"how-can-i-contribute"},"How can I contribute?")),(0,a.kt)("p",null,"If you want to help in the data collection for training the model, go to the\nwebsite ",(0,a.kt)("a",{parentName:"p",href:"https://open-models-iecho.io/"},"https://open-models-iecho.io/"),"."),(0,a.kt)("p",null,"If you want to contribute code, take a look at the\n",(0,a.kt)("a",{parentName:"p",href:"https://github.com/orgs/open-models-platform/projects/3"},"tasks in GitHub")," and comment on an\nissue stating your wish to be assigned. You can also take a look at this\n",(0,a.kt)("a",{parentName:"p",href:"https://github.com/open-models-platform/open-models-iecho/blob/main/CONTRIBUTING.md"},"contributing guide"),".")),(0,a.kt)("details",null,(0,a.kt)("summary",null,(0,a.kt)("h3",{id:"what-technologies-are-used"},"What technologies are used?")),(0,a.kt)("p",null,"The Python backend for the data collection app as well as for the inference\nbackend uses FastAPI. The frontend is built with NextJS and Typescript."),(0,a.kt)("p",null,"The ML codebase is largely PyTorch-based and uses HuggingFace Transformers as\nwell as accelerate, DeepSpeed, bitsandbytes, NLTK, and other libraries.")),(0,a.kt)("h2",{id:"questions-about-the-data-collection-website"},"Questions about the data collection website"),(0,a.kt)("details",null,(0,a.kt)("summary",null,(0,a.kt)("h3",{id:"can-i-use-chatgpt-to-help-in-training-open-models-iecho-for-instance-by-generating-answers"},"Can I use ChatGPT to help in training Open Models iEcho, for instance, by generating answers?")),(0,a.kt)("p",null,"No, it is against their terms of service to use it to help train other models.\nSee\n",(0,a.kt)("a",{parentName:"p",href:"https://github.com/open-models-platform/open-models-iecho/issues/471#issuecomment-1374392299"},"this issue"),".\nChatGPT-like answers will be removed.")),(0,a.kt)("details",null,(0,a.kt)("summary",null,(0,a.kt)("h3",{id:"what-should-i-do-if-i-dont-know-how-to-complete-the-task-as-an-assistant"},"What should I do if I don't know how to complete the task as an assistant?")),"Skip it."),(0,a.kt)("details",null,(0,a.kt)("summary",null,(0,a.kt)("h3",{id:"should-i-fact-check-the-answers-by-the-assistant"},"Should I fact check the answers by the assistant?")),(0,a.kt)("p",null,"Yes, you should try. If you are not sure, skip the task.")),(0,a.kt)("details",null,(0,a.kt)("summary",null,(0,a.kt)("h3",{id:"how-can-i-see-my-score"},"How can I see my score?")),(0,a.kt)("p",null,"In your ",(0,a.kt)("a",{parentName:"p",href:"https://open-models-iecho.io/account"},"account settings"),".")),(0,a.kt)("details",null,(0,a.kt)("summary",null,(0,a.kt)("h3",{id:"can-we-see-how-many-data-points-have-been-collected"},"Can we see how many data points have been collected?")),(0,a.kt)("p",null,"You can see a regularly updated interface at\n",(0,a.kt)("a",{parentName:"p",href:"https://open-models-iecho.io/stats"},"https://open-models-iecho.io/stats"),".")),(0,a.kt)("details",null,(0,a.kt)("summary",null,(0,a.kt)("h3",{id:"how-do-i-write-and-label-prompts"},"How do I write and label prompts?")),(0,a.kt)("p",null,"Check the\n",(0,a.kt)("a",{parentName:"p",href:"https://projects.open.models.platform/open-models-iechocho/docs/guides/guidelines"},"guidelines"),".")),(0,a.kt)("details",null,(0,a.kt)("summary",null,(0,a.kt)("h3",{id:"where-can-i-report-a-bug-or-create-a-new-feature-request"},"Where can I report a bug or create a new feature request?")),(0,a.kt)("p",null,"In the ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/open-models-platform/open-models-iecho/issues"},"GitHub issues"),".")),(0,a.kt)("details",null,(0,a.kt)("summary",null,(0,a.kt)("h3",{id:"why-am-i-not-allowed-to-write-about-this-topic-even-though-it-isnt-illegal"},"Why am I not allowed to write about this topic, even though it isn't illegal?")),(0,a.kt)("p",null,"We want to ensure that the Open Models iEcho dataset is as accessible as possible.\nAs such, it's necessary to avoid any harmful or offensive content that could be\ngrounds for removal on sites such as Hugging Face. Likewise, we want the model\nto be trained to reject as few questions as possible, so it's important to not\ninclude prompts that leave the assistant with no other choice but to refuse in\norder to avoid the generation of harmful content.")),(0,a.kt)("h2",{id:"questions-about-the-development-process"},"Questions about the development process"),(0,a.kt)("details",null,(0,a.kt)("summary",null,(0,a.kt)("h3",{id:"docker-compose-instead-of-docker-compose"},"Docker-Compose instead of Docker Compose")),(0,a.kt)("p",null,"If you are using ",(0,a.kt)("inlineCode",{parentName:"p"},"docker-compose")," instead of ",(0,a.kt)("inlineCode",{parentName:"p"},"docker compose"),' (note the " "\ninstead of the "-"), you should update your docker cli to the latest version.\n',(0,a.kt)("inlineCode",{parentName:"p"},"docker compose")," is the most recent version and should be used instead of\n",(0,a.kt)("inlineCode",{parentName:"p"},"docker-compose"),"."),(0,a.kt)("p",null,"For more details and information check out\n",(0,a.kt)("a",{parentName:"p",href:"https://stackoverflow.com/questions/66514436/difference-between-docker-compose-and-docker-compose"},"this StackOverflow thread"),"\nthat explains it all in detail.")),(0,a.kt)("details",null,(0,a.kt)("summary",null,(0,a.kt)("h3",{id:"enable-dockers-buildkit-backend"},"Enable Docker's BuildKit Backend")),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://docs.docker.com/build/buildkit/"},"BuildKit")," is Docker's new and improved\nbuilder backend. In addition to being faster and more efficient, it supports\nmany new features, among which is the ability to provide a persistent cache,\nwhich outlives builds, to compilers and package managers. This is very useful to\nspeed up consecutive builds, and is used by some container images of\nOpenAssistant's stack."),(0,a.kt)("p",null,"The BuildKit backend is used by\n",(0,a.kt)("a",{parentName:"p",href:"https://www.docker.com/blog/announcing-compose-v2-general-availability/"},"default by Compose V2"),"\n(see above). ",(0,a.kt)("br",null)," But if you want to build an image with ",(0,a.kt)("inlineCode",{parentName:"p"},"docker build")," instead\nof ",(0,a.kt)("inlineCode",{parentName:"p"},"docker compose build"),", you might need to enable BuildKit."),(0,a.kt)("p",null,"To do so, just add ",(0,a.kt)("inlineCode",{parentName:"p"},"DOCKER_BUILDKIT=1")," to your environment."),(0,a.kt)("p",null,"For instance:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},"export DOCKER_BUILDKIT=1\n")),(0,a.kt)("p",null,"You could also, more conveniently,\n",(0,a.kt)("a",{parentName:"p",href:"https://docs.docker.com/build/buildkit/#:~:text=To%20enable%20docker%20BuildKit%20by%20default"},"enable BuildKit by default"),",\nor use\n",(0,a.kt)("a",{parentName:"p",href:"https://docs.docker.com/build/#:~:text=The%20new%20client%20Docker%20Buildx"},"Docker Buildx"),".")),(0,a.kt)("details",null,(0,a.kt)("summary",null,(0,a.kt)("h3",{id:"pre-commit"},"Pre-commit")),(0,a.kt)("p",null,"We are using pre-commit to ensure the quality of the code as well as the same\ncode standard."),(0,a.kt)("p",null,"The steps that you need to follow to be able to use it are:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"# install the pre-commit Python package\npip3 install pre-commit\n\n# install pre-commit to the Git repo to run automatically on commit\npre-commit install\n")),(0,a.kt)("p",null,"So from now on, in your next commits it will run the ",(0,a.kt)("inlineCode",{parentName:"p"},"pre-commit")," on the files\nthat have been staged. Most formatting issues are automatically resolved by the\nhooks so the files can simply be re-added and you can commit. Some issues may\nrequire manual resolution."),(0,a.kt)("p",null,"If you wish to run pre-commit on all files, not just ones your last commit has\nmodified, you can use ",(0,a.kt)("inlineCode",{parentName:"p"},"pre-commit run --all-files"),".")),(0,a.kt)("details",null,(0,a.kt)("summary",null,(0,a.kt)("h3",{id:"docker-cannot-start-container-permission-denied"},"Docker Cannot Start Container: Permission Denied")),(0,a.kt)("p",null,"Instead of running docker with the root command always, you could create a\n",(0,a.kt)("inlineCode",{parentName:"p"},"docker")," group with granted permissions (root):"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"# Create new linux user\nsudo groupadd docker\n\n# Add the actual user to the group\nsudo usermod -aG docker $USER\n\n# Log in the group (apply the group changes to actual terminal session)\nnewgrp docker\n")),(0,a.kt)("p",null,"After that, you should be able to run docker: ",(0,a.kt)("inlineCode",{parentName:"p"},"docker run ."),". In the case you\nstill are not able, can try to reboot terminal:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"reboot\n"))),(0,a.kt)("details",null,(0,a.kt)("summary",null,(0,a.kt)("h3",{id:"docker-cannot-stop-container"},"Docker Cannot Stop Container")),(0,a.kt)("p",null,"If you try to shut down the services (",(0,a.kt)("inlineCode",{parentName:"p"},"docker-compose down"),"), and you are\ngetting permission denied (using root user), you can try the following:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"# Restart docker daemon\nsudo systemctl restart docker.socket docker.service\n\n# And remove the container\ndocker rm -f <container id>\n"))),(0,a.kt)("details",null,(0,a.kt)("summary",null,(0,a.kt)("h3",{id:"docker-port-problems"},"Docker Port Problems")),(0,a.kt)("p",null,"Oftentimes people already have some Postgres instance running on the dev\nmachine. To avoid port problems, change the ports in the ",(0,a.kt)("inlineCode",{parentName:"p"},"docker-compose.yml")," to\nones excluding ",(0,a.kt)("inlineCode",{parentName:"p"},"5433"),", like:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Change ",(0,a.kt)("inlineCode",{parentName:"li"},"db.ports")," to ",(0,a.kt)("inlineCode",{parentName:"li"},"- 5431:5431"),"."),(0,a.kt)("li",{parentName:"ol"},"Add ",(0,a.kt)("inlineCode",{parentName:"li"},"POSTGRES_PORT: 5431")," to ",(0,a.kt)("inlineCode",{parentName:"li"},"db.environment")),(0,a.kt)("li",{parentName:"ol"},"Change ",(0,a.kt)("inlineCode",{parentName:"li"},"webdb.ports")," to ",(0,a.kt)("inlineCode",{parentName:"li"},"- 5432:5431")),(0,a.kt)("li",{parentName:"ol"},"Add ",(0,a.kt)("inlineCode",{parentName:"li"},"POSTGRES_PORT: 5431")," to ",(0,a.kt)("inlineCode",{parentName:"li"},"db.environment")),(0,a.kt)("li",{parentName:"ol"},"Add ",(0,a.kt)("inlineCode",{parentName:"li"},"- POSTGRES_PORT=5432")," to ",(0,a.kt)("inlineCode",{parentName:"li"},"backend.environment")),(0,a.kt)("li",{parentName:"ol"},"Change ",(0,a.kt)("inlineCode",{parentName:"li"},"web.environment.DATABASE_URL")," to\n",(0,a.kt)("inlineCode",{parentName:"li"},"postgres://postgres:postgres@webdb:5432/oasst_web")))))}h.isMDXComponent=!0}}]);